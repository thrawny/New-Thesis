\chapter{Results and Discussion}
\label{chap:results}

In this chapter we present results from the evaluation phase. Given the iterative nature of design research, some adjustments were made between iterations. While we began looking at two different NoSQL databases and one relational database to use for implementing archive prototypes, we ended up moving forward with only Elasticsearch and TokuDB. This was due to an increased knowledge over time about the domain, archive use cases and the technologies themselves. Following the initial iterations, we came to the conclusion that Elasticsearch was the more interesting of the two NoSQL alternatives to pursue further and that doing so would yield more interesting results. Still, to have something to relate it the descision was made to do also perform most of evaluation points for TokuDB as well.
As such, the results included in this section focus on the last iteration of development where all focus was put on Elasticsearch and TokuDB. 

\section{Testing environment}
Access was given to a dedicated server\footnotemark\ in order to achieve more control of the environment so as to get more dependable measurements. However, it should emphasized that the the purpose of doing the measurements was not to perform an experiment and we do not claim to have done so. Instead, the goal was to assess initial feasibility of the solutions and see if they would perform in an adequate manner. More specifically, we ask if the measurements of disk usage, memory utilization, insertion time, query response time etc.\ are good enough to warrant going forward beyond prototype construction.

\footnotetext{Specs: Redhat Linux 6.6, 256GB RAM, 2TB storage}


\section{Data separation}
For evaluation and testing purposes, access was given to a CIMS instance with a database containing about 2 years worth of data (see figure~\ref{fig:jeTrend}), where the job event table contains about 480 million rows. This is the largest database with real data that could be safely accessed for evaluation purposes, without disturbing production environments. Using the developed software components for transforming and migrating data, all relevant data from the CIMS instance was moved to the databases of the archive prototypes.

%Some measurements were done during the migration process, specifically how much time the process took. This was done mainly to get ball park figures to answer if the expected time is likely to be hours, days or weeks.

\section{Query support}

The set of important queries defined in section~\ref{sec:usecases} has been implemented for the archive prototype using Elasticsearch. This section describes the outcome of this implementation along with reasoning about the complexity of the queries.  

The set of important queries translated based on the non-relational schema (section~\ref{nosqlmodel}) was defined previously in section~\ref{sec:archiveapi}. These queries were implemented as part of an API component than can be used to for testing purposes and by other systems. Implementation of all queries was successful in the sense that the queries can certainly be expressed using the query language of ES, if application side joins are allowed. However, how the effectiveness of the queries is highly dependent on the design of the non relational schema. Several differences in query properties of the archive prototype compared to the CIMS database has been noted, as is to be expected. Due to the denormalization of data, fewer joins are required for the non-relational databases and the joins that are performed are done on the application level. Joins on this level leads to more round trips to the database, but lightens the computational resources used by the database. As long as application side joins are simple in nature, i.e.\ fetch one record, get its id and fetch related records, we believe using application side joins are acceptable. For anything else, data should be denormalized so that joins are not needed. It should also be noted that Elasticsearch provides native joins through a parent/child API. We did however not have time to explore this functionality but instead decided to use application side joins.

%\hiddensubsection{Elasticsearch}


%\hiddensubsection{MongoDB}
%
%Vad skiljer sig mysql queriesen mot nosql:
%    * Joins görs på applikationsnivå
%    * Mer roundtrips
%    * Index på allt (es)
%    * Ad hoc queries (es)
%    * Fri text sök, could enable better data analysis (es)

%\begin{table}[h]
%\begin{tabular}{|l|l|l|}
%\hline
%\textbf{High level query}                & \textbf{Supported} & \textbf{Comment}           \\ \hline
%Get build                                    & Y                                                                                        &                            \\ \hline
%Get build information                        & Y                                                                                        &                            \\ \hline
%Get build for root test suite                & Y                                                                                        &                            \\ \hline
%Get trouble reports for build                & Y                                                                                        &                            \\ \hline
%Get trouble report fixes for build           & Y                                                                                        &                            \\ \hline
%Get trouble reports for product and revision & Y                                                                                        &                            \\ \hline
%Get test suite children                      & Y                                                                                        &                            \\ \hline
%Get test case in build                       & Y                                                                                        &                            \\ \hline
%Get test suite in build                      & Y                                                                                        &                            \\ \hline
%Get root test suite for test case/test suite & Y                                                                                        &                            \\ \hline
%Get test case by name                        & Y                                                                                        & Used for test case history \\ \hline
%Get test suite for test case                 & Y                                                                                        &                            \\ \hline
%Get test case history                        & P                                                                                        & Tags not supported         \\ \hline
%Get test tree                                & P                                                                                        & Runs slow for large trees  \\ \hline
%\end{tabular}
%\caption{Possible values in the supported column are yes/no/partially.}
%\label{tab:archivequeries}
%\end{table}

%\section{Schema evolution}
%Not yet addressed

\section{Scalability}
\subsection{Disk usage}
The first migration performed was that of the previously mentioned CIMS instance with 480 million rows in the job event table. Disk usage is presented in figure~\ref{fig:disc}. In order to perform larger migrations, dummy job event data was generated up to a total of 3.3 billion documents/rows and inserted into the archive databases (see figure~\ref{fig:discbig}). The dummy data was similar in both structure and object size compared to the real data. The reason for not going beyond 3.3 billion was simply that the testing environment had 2TB of local storage. However, with current growth trends, 3.3 billion documents/rows would still represent several years worth of historical data.

\begin{figure}[h!]
\centering
\begin{tikzpicture}
\begin{axis}[
    ybar,
    enlargelimits=0.15,
    legend style={at={(0.5,-0.2)},
      anchor=north,legend columns=-1, },
    xlabel={Job Events (Million)},
    ylabel={Disk Usage (GB)},
    symbolic x coords={480},
    xtick=data,
    nodes near coords,
    nodes near coords align={vertical},
    ]
\addplot coordinates {(480,180)};
\addplot coordinates {(480,259)};
\addplot coordinates {(480,550)};
\addplot coordinates {(480,108)};
\legend{MongoDB,ElasticSearch,InnoDB, TokuDB}
\end{axis}
\end{tikzpicture}
\caption{Disk usage after migrating data from CIMS instance with real data.}
\label{fig:disc}
\end{figure}

\begin{figure}[h!]
\centering
\begin{tikzpicture}
\begin{axis}[
    ybar,
    enlargelimits=0.15,
    legend style={at={(0.5,-0.2)},
      anchor=north,legend columns=-1, },
    xlabel={Job Events (Billion)},
    ylabel={Disk Usage (GB)},
    symbolic x coords={3.3},
    xtick=data,
    nodes near coords,
    nodes near coords align={vertical},
    ]
\addplot coordinates {(3.3, 1550)};
\addplot coordinates {(3.3, 800)};
\legend{ElasticSearch,TokuDB}
\end{axis}
\end{tikzpicture}
\caption{Disk usage after having a combination of real data and generated data.}
\label{fig:discbig}
\end{figure}

\subsection{Memory utilization}

\hiddensubsubsection{Elasticsearch}
In Elasticsearch some configuration related to memory usage is needed to achieve stable performance. It is recommended to set the JVM heap size that ES uses to no more than half of total RAM available but never no more than 32GB \cite{ESmemory}. Elasticsearch will typically use more memory than just the heap size, but this usage will be delegated to the operating system. Tests were done with 8GB, 16GB and 32GB heap size for both querying and insertion. Insertion using an 8GB heap would make Elasticsearch crash since garbage collection could not keep up. But 16 and 32GB gave stable insertion performance. However, there was no observable difference in insertion rates between 16 and 32GB heap sizes. Notably, when doing bulk insertion Elasticsearch would quickly reserve half of available system memory but no more (according to the default configuration). So insertion rates seem to scale with available RAM.

On the other hand querying was different. Performing many subsequent queries would not pool RAM like insertion did. Also no positive effect on response time could be observed by increasing the heap size. Elasticsearch was stable with 8, 16 and 32 heap sizes and response times were the same. 

%\hiddensubsubsection{MongoDB}
%
%Working set estimations are presented in figure~\ref{fig:ws}. Initial estimations of the working set for MongoDB have been done with manual testing. As long as custom indexes defined on the job event collection fit in RAM, the database is stable and can respond to queries where indexes can be utilized. The working set estimation is the summed size of the custom indexes.
%
%\begin{figure}[h!]
%\centering
%\begin{tikzpicture}
%\begin{axis}[
%    ybar,
%    enlargelimits=0.15,
%    legend style={at={(0.5,-0.2)},
%      anchor=north,legend columns=-1, },
%    xlabel={Job Events (Billion)},
%    ylabel={Memory Utilization (GB)},
%    symbolic x coords={2,3.3},
%    xtick=data,
%    nodes near coords,
%    nodes near coords align={vertical},
%    ]
%\addplot coordinates {(2,6) (3.3,12)};
%\addplot coordinates {(2,1) (3.3,1)};
%\addplot coordinates {(2,1) (3.3,1)};
%\legend{MongoDB,ElasticSearch,MySQL}
%\end{axis}
%\end{tikzpicture}
%\caption{Working set estimation}
%\label{fig:ws}
%\end{figure}

\subsection{Insertion time}

\hiddensubsubsection{Elasticsearch}
Elasticsearch was configured to use a 1 node setup. The CIMS instance with 480 million job events was then migrated. With this configuration the process took 21 hours. This figure is not very reliable since it is also dependent on the database server of the CIMS instance. To get more dependable results we measured insertion rates for dummy data up to a total of 3.3 billion documents. The generation of data was performed locally. During the insertion of dummy data we could achieve a mean insertion rate of about 33 million documents per hour. What is very notable here is that even using a 1 node setup we observed little to no performance degradation for insert rates when the total data set grew. So when going from 0 documents to 3.3 billion the insert rate was as far as we could observe constant. In figure~\ref{fig:insert_rate}, we present a graph of insertion rates in relation to data set size.
\begin{figure}[h!]
\centering
\includegraphics[]{figure/insert_rate.png}
\caption{Insertion rate of dummy job event data into Elasticsearch.}
\label{fig:insert_rate}
\end{figure}

When switching to a cluster with 4 nodes (4 ES instances running on the same machine), much greater insert rates could be achieved and we observed over 60 million per hour in this case.

These reported insertion rates were achieved with little configuration of Elasticsearch. The only important configuration variable to set is the JVM heap size, which as previously mentioned was set to a minimum of 16GB to get stable performance. When performing the actual inserts, bulk inserts were used as opposed to inserting one document at a time. Elasticsearch exposes a bulk insert API that is highly recommended to use when inserting a high number of documents.

%\hiddensubsubsection{MongoDB}

\hiddensubsubsection{TokuDB}

\subsection{Query response time}

\hiddensubsubsection{Elasticsearch}
Measurements were made in regards to query response time with the large data set (3.3 billion documents) containing dummy job events. We looked specifically at two queries in this case, namely to look up a job event by its name (used for creating test case histories) and to look up all children for a job event (used to create a test tree). For the former query, the result set will grow as the overall data set grows, since more and more test cases with a specific name is inserted. Another interesting thing to note about this query is that data retrieval is random across the data set since test cases with the same name exist in many builds spanning years of time.

For the latter, the result set size will likely grow much more slowly. It is not dependent on the overall data set size but instead depends on if the size of test suites grow. This is in the hands of the developers who construct the test suites. In comparison to looking up a test case by name, looking up test suite children is not random across the entire data set. This because test cases from the same build and test suite are inserted together. As such, querying for test suite children should be faster than querying by test case name. But the response time is also highly dependant on the size of the result set.

These two queries should be gain some indication to the effectiveness of Elasticsearch is when querying on large data sets. In figure~\ref{fig:query_by_name} the response times when querying by name is shown. The figure has 500 data points in total, where for each points a name is selected randomly from a list of all names of test cases from one CIMS instance. There are about 16000 unique names in total. The outliers in the figure are due to that a name was selected more than once and results where cached for the second the time query was executed with the same name. Notably, the response time is long for this query because of the large result sets. If the whole result set is not needed but say, only the first few hundred hits, which is a more realistic scenario in every day usage, the response time would be just a few seconds.

\begin{figure}[h!]
\centering
\includegraphics[]{figure/query_by_name.png}
\caption{Query response time in Elasticsearch when looking up job events by name.}
\label{fig:query_by_name}
\end{figure}


%Get job event ny name \\
%asddfgsdf, 90 seconds, 60k events \\
%alsjkd, 90 seconds, 60k events \\
%askdlj, 90 seconds, 60k events \\
%aslkdjasd, 90 seconds, 60k events \\
%oipioipi, 90 seconds, 60k events \\
%iyuiytyuie, 90 seconds, 60k events \\
%
%Get job event children \\
%2394234-290384, 5 seconds, 1k events \\
%2394234-290384, 5 seconds, 1k events \\
%2394234-290384, 5 seconds, 1k events \\
%2394234-290384, 5 seconds, 1k events \\
%2394234-290384, 5 seconds, 1k events \\
%2394234-290384, 5 seconds, 1k events \\

\subsection{Horizontal Scalability}
While Elasticsearch performed well in our tests using a single node setup with large data sets, having the possibility to go smoothly from single node to cluster is important to consider. Before adding more nodes to an Elasticsearch cluster, the amount of shards per index must be defined as it sets the upper bound for the total amount possible nodes in the cluster.

In ES, all data in an index is split up into shards. These shards can themselves not be split and as such, one shard is always stored in its entirety on a single node. However, nodes can store multiple shards from the same index, as is the case in the single node setup that was tested on. In this setup, four total shards were predefined per index. For production, the total number of shards is typically set to a much higher amount. 

Given the setup that was predefined, the maximum number of deployable nodes was four. The single node setup was then converted to a four node cluster where all nodes resided on the testing machine. Doing the conversion was as trivial as starting a new ES process configured with the same cluster name an already running ES process. The cluster then automatically handles shard allocation to available nodes.


%Not yet addressed
%Här borde vi kunna skriva tekniska saker, men från de tekniska saker dra slutsater i Discussion som svarar på om dessa tekniker ger något business value?
%%\hiddensubsubsection{MongoDB}
%\hiddensubsubsection{Elasticsearch}
%"Lessons learned while scaling with Elasticsearch, future work can be to test with more nodes".\\
%Compared to MongoDB, horizontal scaling with Elasticsearch demands more configuration upfront in order to get a suitable cluster.
%In MongoDB, an arbitrary number of nodes can be added to the cluster. The maximum number of nodes in an Elasticsearch cluster can never be higher then the total amount of shards, which must be defined when an index (collection of documents) is created.
%
%%This restriction depends on how Elasticsearch is scaling in an horizontal manner. The partitioning of data when adding new nodes to a cluster is dependent on how many shards the initial node holds, as an new node is added to the cluster it overtakes shards from the already existing nodes.
%
%\hiddensubsubsection{TokuDB}

\section{Integration with CIMS}
Proof of concept functionality was requested by stakeholders at Ericsson to demonstrate the possibility of integrating the archive with CIMS and the suitability of polyglot persistence. As mentioned previously, the viewing of builds was selected as a suitable piece of functionality to evolve to use the archive. It was possible with reasonable effort to implement a new build viewer in CIMS that used the archive API to present build data. However, the view was somewhat simplified given time constraints and because of the way CIMS is designed, where it is not always pain free to change the underlying data source for web page components. We do maintain that this it is possible to do if the system is redesigned somewhat to reduce coupling between models and views.

To demonstrate the new archive build viewer we used the following somewhat contrived use case as a basis; \\
- Initially the archive is empty \\
- User views list of all builds. \\
- User identifies build that has a reference build. \\
- User deletes the reference build.  \\
- System moves build to archive before it is deleted.  \\
- User requests to view reference build. \\
- System presents data about reference build using the archive API. \\

%Initially the archive contains no data. A user views the list of all builds and finds a build that has a reference build. The user then goes on to delete the reference build. Before the build is deleted from the relational database it is first migrated to the archive. Then when requesting to view the reference build, the archive will be used to present it instead of the relational database. On this new build page it can be noted that it is the archive that is used as the underlying data source and the page also contains links to view the raw build and test data in Elasticsearch.

This use case is mostly used for demonstration purposes and we believe a more realistic way of moving data from the live database to the archive would be to use scheduled jobs that do this on for example a weekly basis.

\section{Organizational suitability}
This section describes the organizational suitability of two archive prototypes.

%\hiddensubsection{MongoDB}

\hiddensubsection{Elasticsearch}
There are a few reasons as to why we believe using ES would work well for the organization. First of all, CIMS already employs a number of different data stores other than MySQL. In some sense it is already a polyglot persistence solution as it makes use of Redis, Sphinx and RabbitMQ. So when developing CIMS it is required to be familiar multiple databases and their respective ways of representing data. Going from this situation to also using Elasticsearch should not be considered very problematic. Through discussions with the CIMS development team this opinion is somewhat cemented as they are very open to discussing and trying out new technologies and have been doing so before this thesis was conducted. 

In an article by Stonebraker and Catell \cite{10rules}, several rules are given to aid the selection of what they classify as simple operation data stores, namely databases that scale horizontally and avoid complex operations like cross node joins. One notable rule is to consider out-of-the-box behaviour of a candidate database. The better this behaviour is the less of a pain it will be to initially configure the candidate database. We, the authors of this thesis, do not make any claim to be database experts but our experience of Elasticsearch and its out-of-the-box behaviour is certainly positive in many respects. The amount of configuration to get stable performance was minimal. As mentioned earlier, the only variable we had to consider in order to get stable performance was the JVM heap size. On top of this, it was easy to go from a single node setup to a cluster. 

However, while the initial configuration was pain free, there are many things to consider when it comes to schema and query design in Elasticsearch. For example, it is important to know upfront what kinds of queries that the field of a document or the document as a whole should support. Notably, if a field requires to be queried on by an exact value comparison, this must be configured upfront (typically by declaring the field as 'not analyzed'). As such, most of the time spent on Elasticsearch was not done configuring the database but rather optimizing schemas and exploring the rich query possibilities.

Overall, we think Elasticsearch is a interesting candidate to consider moving forward and see no real problems as to why it would not be possible to use, taking the organizational context into consideration.

\hiddensubsection{TokuDB}
Since TokuDB is a storage engine for MySQL, for this solution the live database and the archive would be identical for everything but the storage engine. As such, this solution has very little friction to use as everyone working with CIMS is already very knowledgeable about relational databases and MySQL in particular. The solution is simple and would solve many of identified problems related to monotonic data growth. Through the other points of evaluation for TokuDB we have shown that using TokuDB as a storage engine it is very possible to scale to billions of rows on a single machine when it comes to both insertion rate and query performance.